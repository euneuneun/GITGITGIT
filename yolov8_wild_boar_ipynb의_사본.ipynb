{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP43ASnhnj5Xp7Fz0YUQ1nB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/euneuneun/GITGITGIT/blob/main/yolov8_wild_boar_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['LC_ALL'] = 'en_US.UTF-8'\n",
        "os.environ['LANG'] = 'en_US.UTF-8'\n",
        "os.environ['LANGUAGE'] = 'en_US.UTF-8'"
      ],
      "metadata": {
        "id": "gbLeAtIvYWjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "8lqWQAhJ3gvL",
        "outputId": "8ae22a5f-40ea-4a1b-92ad-cd2be8c5fb73"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "A UTF-8 locale is required. Got ANSI_X3.4-1968",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-c2470c46cf68>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install ultralytics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "n1KSFIZW8ewY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,sys\n",
        "from google.colab import drive ## 구글 콜랩에서 구글 드라이브를 마운트하는 데 사용\n",
        "\n",
        "drive.mount('/content/gdrive') ## 구글 드라이브를 /content/gdrive 경로에 마운트\n",
        "\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive ## /content/gdrive/My Drive/ 경로를 /mydrive에 심볼릭 링크로 만듬\n",
        "!ls /mydrive ## /mydrive에 있는 파일 및 폴더를 나열.\n",
        "\n",
        "!mkdir \"/mydrive/ultra_workdir\" ## /mydrive에 ultra_workdir이라는 이름의 새 디렉토리를 만듬"
      ],
      "metadata": {
        "id": "lxvYnrce6XJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/data2; unzip Project2.v2i.yolov8.zip"
      ],
      "metadata": {
        "id": "5XHdHTKl6Xvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "model.train(data = \"/content/data2/data.yaml\",epochs = 15, imgsz = 640, project = \"/content/gdrive/MyDrive/ultra_workdir\",name = \"wild\", exist_ok = True)"
      ],
      "metadata": {
        "id": "E_5DcnNRAgJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "h1IvH3_WACsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"/content/gdrive/MyDrive/ultra_workdir/wild/weights/best.pt\")\n",
        "\n",
        "results = model.predict(\"/content/data2/test/images/1--281-_jpg.rf.2b08f0c842781c8edaeb638623d23091.jpg\",line_thickness = 2)\n",
        "\n",
        "res_plot = results[0].plot()\n",
        "\n",
        "plt.imshow(res_plot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FQr2NTBqA8Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "TmLX9AyRqxws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 결과 딕셔너리\n",
        "results_dict = {\n",
        "    'metrics/precision(B)': 0.4347980114478331,\n",
        "    'metrics/recall(B)': 0.23247232472324722,\n",
        "    'metrics/mAP50(B)': 0.19870567434925188,\n",
        "    'metrics/mAP50-95(B)': 0.07180046737975773,\n",
        "    'fitness': 0.08449098807670714\n",
        "}\n",
        "\n",
        "# 성능 지표 키와 값을 추출\n",
        "metrics = list(results_dict.keys())\n",
        "values = list(results_dict.values())\n",
        "\n",
        "# 바 그래프로 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(metrics, values, color='skyblue')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Object Detection Metrics')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "crA40UKAKYws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 결과 데이터\n",
        "precision = 0.973\n",
        "recall = 0.417\n",
        "mAP50 = 0.464\n",
        "mAP50_95 = 0.328\n",
        "\n",
        "# 시각화\n",
        "categories = ['Box(Precision)', 'Box(Recall)', 'mAP50', 'mAP50-95']\n",
        "scores = [precision, recall, mAP50, mAP50_95]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(categories, scores, color=['blue', 'green', 'orange', 'red'])\n",
        "plt.title('Object Detection Performance')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)  # 점수 범위 (0~1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qVWOskBFrez3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 결과 데이터\n",
        "precision = 0.9605483588413889\n",
        "recall = 0.36458\n",
        "mAP50 = 0.4448137\n",
        "mAP50_95 = 0.303352245\n",
        "\n",
        "# 시각화\n",
        "categories = ['Box(Precision)', 'Box(Recall)', 'mAP50', 'mAP50-95']\n",
        "scores = [precision, recall, mAP50, mAP50_95]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(categories, scores, color=['blue', 'green', 'orange', 'red'])\n",
        "plt.title('Object Detection Performance')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)  # 점수 범위 (0~1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EdGY4SJJqSoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "\n",
        "# YOLO 모델 로드\n",
        "model = YOLO(\"/content/gdrive/MyDrive/ultra_workdir/wild/weights/best.pt\")\n",
        "\n",
        "# 웹캠 비디오 스트리밍을 위한 JavaScript 코드\n",
        "def start_webcam():\n",
        "    js = \"\"\"\n",
        "    var video = document.createElement('video');\n",
        "    document.body.appendChild(video);\n",
        "    video.style.display = 'none';\n",
        "\n",
        "    navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {\n",
        "        video.srcObject = stream;\n",
        "        video.play();\n",
        "    });\n",
        "\n",
        "    var canvas = document.createElement('canvas');\n",
        "    canvas.width = 640;\n",
        "    canvas.height = 480;\n",
        "    document.body.appendChild(canvas);\n",
        "    const fps = 10;\n",
        "\n",
        "    function capture() {\n",
        "        setTimeout(() => {\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "            var img = canvas.toDataURL('image/jpeg', 0.8);\n",
        "            google.colab.kernel.invokeFunction('notebook.run_object_detection', [img], {});\n",
        "            capture();\n",
        "        }, 1000 / fps);\n",
        "    }\n",
        "\n",
        "    capture();\n",
        "    \"\"\"\n",
        "\n",
        "    display(eval_js(js))\n",
        "\n",
        "# 웹캠에서 캡처된 이미지를 처리하고 객체 감지 결과를 표시하는 함수\n",
        "def run_object_detection(img_data):\n",
        "    # 이미지를 OpenCV 형식으로 디코딩\n",
        "    img = cv2.imdecode(np.frombuffer(b64decode(img_data.split(',')[1]), np.uint8), -1)\n",
        "\n",
        "    # 객체 감지\n",
        "    results = model.predict(Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
        "\n",
        "    # 결과를 OpenCV 이미지로 변환하여 표시\n",
        "    for result in results.xyxy[0]:\n",
        "        label = int(result[-1])\n",
        "        cv2.rectangle(img, (result[0], result[1]), (result[2], result[3]), (0, 255, 0), 2)\n",
        "        cv2.putText(img, f'Object {label}', (result[0], result[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imshow('Object Detection', img)\n",
        "    cv2.waitKey(1)\n",
        "\n",
        "# 웹캠 시작\n",
        "start_webcam()\n"
      ],
      "metadata": {
        "id": "W-7A0Jv7uf8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 업로드한 동영상 파일 경로\n",
        "video_path = \"/content/video_01.mp4\"\n",
        "\n",
        "# YOLO 모델 로드\n",
        "model = YOLO(\"/content/gdrive/MyDrive/ultra_workdir/wild/weights/best.pt\")\n",
        "\n",
        "# 동영상 열기\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# 동영상 프레임 처리\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # OpenCV 프레임을 PIL 이미지로 변환\n",
        "    pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # 객체 감지\n",
        "    results = model.predict(pil_img)\n",
        "\n",
        "    # 결과가 이미지를 렌더링할 수 있는지 확인\n",
        "    if hasattr(results, 'render'):\n",
        "        # 결과를 OpenCV 이미지로 변환하여 표시\n",
        "        frame_with_results = cv2.cvtColor(results.render(), cv2.COLOR_RGB2BGR)\n",
        "        plt.imshow(frame_with_results)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# 종료\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "fCyTT1RORgV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# 업로드한 동영상 파일 경로\n",
        "video_path = \"/content/data2/test/video_01.mp4\"\n",
        "\n",
        "# 업로드한 동영상을 읽기 위해 파일 업로드\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 동영상을 열어서 객체 감지\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# YOLO 모델 로드\n",
        "model = YOLO(\"/content/gdrive/MyDrive/ultra_workdir/wild/weights/best.pt\")\n",
        "\n",
        "# 동영상의 각 프레임을 처리\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # PIL 이미지로 변환\n",
        "    pil_img = Image.fromarray(frame)\n",
        "\n",
        "    # 객체 감지\n",
        "    results = model.predict(pil_img)\n",
        "\n",
        "    # 결과를 OpenCV 이미지로 변환하여 출력\n",
        "    frame_with_results = cv2.cvtColor(results.render(), cv2.COLOR_RGB2BGR)\n",
        "    cv2.imshow('Object Detection', frame_with_results)\n",
        "\n",
        "    # 'q' 키를 누르면 종료\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# 종료\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "VIAc9g4lmDAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 동영상의 각 프레임을 처리\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # PIL 이미지로 변환\n",
        "    pil_img = Image.fromarray(frame)\n",
        "\n",
        "    # 객체 감지\n",
        "    results = model.predict(pil_img)\n",
        "\n",
        "    # results가 리스트가 아닌 객체여야 함\n",
        "    # 객체가 이미지를 렌더링할 수 있는 메서드를 제공하는지 확인\n",
        "    if hasattr(results, 'render'):\n",
        "        # 결과를 OpenCV 이미지로 변환하여 출력\n",
        "        frame_with_results = cv2.cvtColor(results.render(), cv2.COLOR_RGB2BGR)\n",
        "        cv2.imshow('Object Detection', frame_with_results)\n",
        "\n",
        "        # 'q' 키를 누르면 종료\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "# 종료\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "dP1GDJs0Qc79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 성능 지표 및 결과 딕셔너리\n",
        "metrics = ['Box(Precision)', 'Box(Recall)', 'mAP50', 'mAP50-95']\n",
        "results_dict = {'Box(Precision)': 0.961, 'Box(Recall)': 0.365, 'mAP50': 0.445, 'mAP50-95': 0.303}\n",
        "\n",
        "# 성능 지표에 따른 결과 값 가져오기\n",
        "values = [results_dict[metric] for metric in metrics]\n",
        "\n",
        "# 그래프 생성\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(metrics, values, color=['blue', 'green', 'red', 'orange'])\n",
        "plt.title('YOLO Model Performance')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4YrFvRn7xGFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/data2; unzip WILDBOAR.v1i.yolov8.zip"
      ],
      "metadata": {
        "id": "8v-_fOVK1zcZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}