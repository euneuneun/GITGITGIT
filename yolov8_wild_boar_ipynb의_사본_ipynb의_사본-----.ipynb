{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/euneuneun/GITGITGIT/blob/main/yolov8_wild_boar_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8-----.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lqWQAhJ3gvL",
        "outputId": "a94bb2d4-6630-462b-8e70-c4e4685f3eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.22-py3-none-any.whl (778 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.4/778.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1KSFIZW8ewY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxvYnrce6XJ8"
      },
      "outputs": [],
      "source": [
        "import os,sys\n",
        "from google.colab import drive ## 구글 콜랩에서 구글 드라이브를 마운트하는 데 사용\n",
        "\n",
        "drive.mount('/content/gdrive') ## 구글 드라이브를 /content/gdrive 경로에 마운트\n",
        "\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive ## /content/gdrive/My Drive/ 경로를 /mydrive에 심볼릭 링크로 만듬\n",
        "!ls /mydrive ## /mydrive에 있는 파일 및 폴더를 나열.\n",
        "\n",
        "!mkdir \"/mydrive/ultra_workdir\" ## /mydrive에 ultra_workdir이라는 이름의 새 디렉토리를 만듬"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "InHfpkwy1Zzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XHdHTKl6Xvc"
      },
      "outputs": [],
      "source": [
        "!cd /content/data; unzip target_boar.v1i.yolov8.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_5DcnNRAgJa"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "model.train(data = \"/content/data/data.yaml\",epochs = 150, imgsz = 640, project = \"/content/drive/MyDrive/ultra_workdir_033\",name = \"wild\", exist_ok = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1IvH3_WACsh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FQr2NTBqA8Q-"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"/content/gdrive/MyDrive/ultra_workdir_02/wild/weights/best.pt\")\n",
        "\n",
        "results = model.predict(\"/content/data2/test/images/google-images-0_jpg.rf.7fe3009499e47d9c73941cfbdf1a5c35.jpg\",line_thickness = 2)\n",
        "\n",
        "res_plot = results[0].plot()\n",
        "\n",
        "plt.imshow(res_plot)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmLX9AyRqxws"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crA40UKAKYws"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 결과 딕셔너리\n",
        "results_dict = {\n",
        "    'metrics/precision(B)': 0.4347980114478331,\n",
        "    'metrics/recall(B)': 0.23247232472324722,\n",
        "    'metrics/mAP50(B)': 0.19870567434925188,\n",
        "    'metrics/mAP50-95(B)': 0.07180046737975773,\n",
        "    'fitness': 0.08449098807670714\n",
        "}\n",
        "\n",
        "# 성능 지표 키와 값을 추출\n",
        "metrics = list(results_dict.keys())\n",
        "values = list(results_dict.values())\n",
        "\n",
        "# 바 그래프로 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(metrics, values, color='skyblue')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Values')\n",
        "plt.title('Object Detection Metrics')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVWOskBFrez3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 결과 데이터\n",
        "precision = 0.4347980\n",
        "recall = 0.232472324\n",
        "mAP50 = 0.19870567\n",
        "mAP50_95 = 0.07180046737\n",
        "\n",
        "# 그래프에 사용할 데이터\n",
        "labels = ['Precision', 'Recall', 'mAP50', 'mAP50-95']\n",
        "values = [precision, recall, mAP50, mAP50_95]\n",
        "\n",
        "# 그래프 그리기\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(labels, values, color=['blue', 'orange', 'green', 'red'])\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Object Detection Performance Metrics')\n",
        "plt.ylim(0, 1)  # y축 범위 설정 (0부터 1까지)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdGY4SJJqSoS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 결과 데이터\n",
        "precision = 0.9605483588413889\n",
        "recall = 0.36458\n",
        "mAP50 = 0.4448137\n",
        "mAP50_95 = 0.303352245\n",
        "\n",
        "# 시각화\n",
        "categories = ['Box(Precision)', 'Box(Recall)', 'mAP50', 'mAP50-95']\n",
        "scores = [precision, recall, mAP50, mAP50_95]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(categories, scores, color=['blue', 'green', 'orange', 'red'])\n",
        "plt.title('Object Detection Performance')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0, 1)  # 점수 범위 (0~1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "W-7A0Jv7uf8p"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "\n",
        "# YOLO 모델 로드\n",
        "model = YOLO(\"/content/gdrive/MyDrive/ultra_workdir_02/wild/weights/best.pt\")\n",
        "\n",
        "# 웹캠 비디오 스트리밍을 위한 JavaScript 코드\n",
        "def start_webcam():\n",
        "    js = \"\"\"\n",
        "    var video = document.createElement('video');\n",
        "    document.body.appendChild(video);\n",
        "    video.style.display = 'none';\n",
        "\n",
        "    navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {\n",
        "        video.srcObject = stream;\n",
        "        video.play();\n",
        "    });\n",
        "\n",
        "    var canvas = document.createElement('canvas');\n",
        "    canvas.width = 640;\n",
        "    canvas.height = 480;\n",
        "    document.body.appendChild(canvas);\n",
        "    const fps = 10;\n",
        "\n",
        "    function capture() {\n",
        "        setTimeout(() => {\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);\n",
        "            var img = canvas.toDataURL('image/jpeg', 0.8);\n",
        "            google.colab.kernel.invokeFunction('notebook.run_object_detection', [img], {});\n",
        "            capture();\n",
        "        }, 1000 / fps);\n",
        "    }\n",
        "\n",
        "    capture();\n",
        "    \"\"\"\n",
        "\n",
        "    display(eval_js(js))\n",
        "\n",
        "# 웹캠에서 캡처된 이미지를 처리하고 객체 감지 결과를 표시하는 함수\n",
        "def run_object_detection(img_data):\n",
        "    # 이미지를 OpenCV 형식으로 디코딩\n",
        "    img = cv2.imdecode(np.frombuffer(b64decode(img_data.split(',')[1]), np.uint8), -1)\n",
        "\n",
        "    # 객체 감지\n",
        "    results = model.predict(Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
        "\n",
        "    # 결과를 OpenCV 이미지로 변환하여 표시\n",
        "    for result in results.xyxy[0]:\n",
        "        label = int(result[-1])\n",
        "        cv2.rectangle(img, (result[0], result[1]), (result[2], result[3]), (0, 255, 0), 2)\n",
        "        cv2.putText(img, f'Object {label}', (result[0], result[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    cv2.imshow('Object Detection', img)\n",
        "    cv2.waitKey(1)\n",
        "\n",
        "# 웹캠 시작\n",
        "start_webcam()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCyTT1RORgV9"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 업로드한 동영상 파일 경로\n",
        "video_path = \"/content/video_01.mp4\"\n",
        "\n",
        "# YOLO 모델 로드\n",
        "model = YOLO(\"/content/gdrive/MyDrive/ultra_workdir/wild/weights/best.pt\")\n",
        "\n",
        "# 동영상 열기\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# 동영상 프레임 처리\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # OpenCV 프레임을 PIL 이미지로 변환\n",
        "    pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # 객체 감지\n",
        "    results = model.predict(pil_img)\n",
        "\n",
        "    # 결과가 이미지를 렌더링할 수 있는지 확인\n",
        "    if hasattr(results, 'render'):\n",
        "        # 결과를 OpenCV 이미지로 변환하여 표시\n",
        "        frame_with_results = cv2.cvtColor(results.render(), cv2.COLOR_RGB2BGR)\n",
        "        plt.imshow(frame_with_results)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# 종료\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIAc9g4lmDAz"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# 업로드한 동영상 파일 경로\n",
        "video_path = \"/content/video_01.mp4\"\n",
        "\n",
        "# 동영상을 열어서 객체 감지\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# YOLO 모델 로드\n",
        "model = YOLO(\"/content/gdrive/MyDrive/ultra_workdir_02/wild/weights/best.pt\")\n",
        "\n",
        "# 동영상의 각 프레임을 처리\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # PIL 이미지로 변환\n",
        "    pil_img = Image.fromarray(frame)\n",
        "\n",
        "    # 객체 감지\n",
        "    results_list = model.predict([pil_img])  # 이미지를 리스트로 전달하여 각 이미지에 대한 결과를 리스트로 받음\n",
        "\n",
        "    # 결과 리스트를 순회하면서 처리\n",
        "    for results in results_list:\n",
        "        # 결과를 시각화하여 이미지로 반환\n",
        "        res_img = results.plot()\n",
        "\n",
        "        # 이미지를 OpenCV 형식으로 변환하여 출력\n",
        "        frame_with_results = cv2.cvtColor(np.array(res_img), cv2.COLOR_RGB2BGR)\n",
        "        cv2_imshow(frame_with_results)  # cv2.imshow 대신 cv2_imshow 사용\n",
        "\n",
        "    # 'q' 키를 누르면 종료\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "# 종료\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dP1GDJs0Qc79"
      },
      "outputs": [],
      "source": [
        "# 동영상의 각 프레임을 처리\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # PIL 이미지로 변환\n",
        "    pil_img = Image.fromarray(frame)\n",
        "\n",
        "    # 객체 감지\n",
        "    results = model.predict(pil_img)\n",
        "\n",
        "    # results가 리스트가 아닌 객체여야 함\n",
        "    # 객체가 이미지를 렌더링할 수 있는 메서드를 제공하는지 확인\n",
        "    if hasattr(results, 'render'):\n",
        "        # 결과를 OpenCV 이미지로 변환하여 출력\n",
        "        frame_with_results = cv2.cvtColor(results.render(), cv2.COLOR_RGB2BGR)\n",
        "        cv2.imshow('Object Detection', frame_with_results)\n",
        "\n",
        "        # 'q' 키를 누르면 종료\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "# 종료\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YrFvRn7xGFr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 성능 지표 및 결과 딕셔너리\n",
        "metrics = ['Box(Precision)', 'Box(Recall)', 'mAP50', 'mAP50-95']\n",
        "results_dict = {'Box(Precision)': 0.961, 'Box(Recall)': 0.365, 'mAP50': 0.445, 'mAP50-95': 0.303}\n",
        "\n",
        "# 성능 지표에 따른 결과 값 가져오기\n",
        "values = [results_dict[metric] for metric in metrics]\n",
        "\n",
        "# 그래프 생성\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(metrics, values, color=['blue', 'green', 'red', 'orange'])\n",
        "plt.title('YOLO Model Performance')\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Values')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v-_fOVK1zcZ"
      },
      "outputs": [],
      "source": [
        "!cd /content/data2; unzip WILDBOAR.v1i.yolov8.zip"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}